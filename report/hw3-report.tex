\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{siunitx}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{enumitem}
\usepackage{parskip}
\usepackage{booktabs}
\usepackage{float}

\pgfplotsset{compat=1.18}

\title{APMA 2822B Homework 3 Report}
\author{Yash Agrawal}
\date{\today}

\begin{document}
\maketitle

\section*{Math Setup}
Assume that $\Delta x = \Delta y = h$. 

Using the second derivative approximations we were given, we have
\[
    f(x, y) = \frac{u[i-1, j] + u[i+1, j] + u[i, j-1] + u[i, j+1] - 4u[i, j]}{h^2}
\]

Substituting in the given $f(x, y)$, we get
\begin{align*}
    -8\pi^2 \sin(2\pi x) \cos(2\pi y) &= \frac{u[i-1, j] + u[i+1, j] + u[i, j-1] + u[i, j+1] - 4u[i, j]}{h^2} \\
    -8\pi^2 h^2 \sin(2\pi x) \cos(2\pi y) &= u[i-1, j] + u[i+1, j] + u[i, j-1] + u[i, j+1] - 4u[i, j]
\end{align*}

Solving for $u[i, j]$, we have
\begin{align*}
    4u[i, j] &= u[i-1, j] + u[i+1, j] + u[i, j-1] + u[i, j+1] + 8\pi^2 h^2 \sin(2\pi x) \cos(2\pi y) \\
    u[i, j] &= \frac{1}{4} \left( u[i-1, j] + u[i+1, j] + u[i, j-1] + u[i, j+1] + 8\pi^2 h^2 \sin(2\pi x) \cos(2\pi y) \right)
\end{align*}

We can use this equation to iteratively solve for $u$ with the given $f(x, y)$ using the Jacobi method. 

We will consider our solution to have converged when the maximum residual in $u$ across all grid points is less than a specified tolerance $\epsilon$.

\section*{Results}

I implemented three versions of the Jacobi iterative solver. One runs sequentially, one uses OpenMP to parallelize using shared memory, and one uses OpenMPI to parallelize using distributed memory. The OpenMP implementation uses 8 threads, and the OpenMPI implementation uses 8 processes. 

I also precompute the values of $f(x, y)$ and store them in an array to avoid recomputing them at every iteration. All my calculations will account for this precomputation in terms of the memory accesses and FLOPs.

All versions produce correct and also exactly identical results at every iteration. They converge when the max residual is less than 0.001. The performance results are summarized below, where N is the size of the array used.

\begin{table}[H]
    \centering
    \begin{tabular}{lrrrr}
        \toprule
        Version & N & Time (s) & GB/s & Iterations \\
        \midrule
        Sequential & 256 & 14.764 & 9.751 & 54,917 \\
        Sequential & 512 & 238.846 & 9.682 & 220,536 \\
        Sequential & 1024 & - & - & - \\
        OpenMP & 256 & 1.973 & 72.657 & 54,917 \\
        OpenMP & 512 & 24.469 & 95.506 & 220,536 \\
        OpenMP & 1024 & 375.660 & 98.686 & 883,877 \\
        OpenMPI & 256 & 2.340 & 61.519 & 54,917 \\
        OpenMPI & 512 & 37.489 & 61.685 & 220,536 \\
        OpenMPI & 1024 & 578.134 & 64.124 & 883,877 \\
        \bottomrule
    \end{tabular}
\end{table}

We can clearly observe that both of parallelism provided massive performance boosts. The OpenMP version performed better than the OpenMPI version by a significant margin. 

\section*{Roofline Model}

\subsection*{FLOPs}

To generate a roofline model, we first need to calculate the number of floating point operations (FLOPs) for our separate operations.

For the loop in which we update our solution, we have the following operations for each grid point:
\begin{itemize}
    \item 4 additions to sum the neighboring u values
    \item 1 multiplication to compute $8\pi^2 h^2$
    \item 2 multiplications to compute $\sin(2\pi x)$ and $\cos(2\pi y)$
    \item 1 multiplication to multiply $8\pi^2 h^2$ with $\sin(2\pi x) \cos(2\pi y)$
    \item 1 addition to add the result to the sum of neighboring u values
    \item 1 division to divide by 4
\end{itemize}

\subsection*{Memory Accesses}

We also need to calculate the memory usage for our separate operations. 

We use double precision floating point numbers for all calculations, which are each 8 bytes. Let the size of the matrix be $N \times N$.

For the loop in which we update our solution, we must read the u matrix, write the new u matrix, and read the f values matrix. This means the number of bytes we access for updating out matrix is
\[
    2 * 8 * N^2 + 8 * N^2 = 24N^2
\]

For the loop in which we calculate our max residual or convergence error, we must read the u matrix and the f values matrix. This gives the number of bytes accessed as
\[
    8 * N^2 + 8 * N^2 = 16N^2
\]

\end{document}